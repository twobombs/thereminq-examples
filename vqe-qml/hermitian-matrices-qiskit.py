# from paper
# generated by gemini25 - unfinised because of qiskit migration - use pyqrack variant

import numpy as np
from qiskit import QuantumCircuit
from qiskit.circuit import Parameter, ParameterVector
from qiskit.quantum_info import SparsePauliOp, Statevector
from qiskit.primitives import Estimator
from qiskit.circuit.library import ZFeatureMap, TwoLocal

# --- Helper function to construct a parameterized Hermitian observable ---
def create_hermitian_observable(params_obs, num_qubits):
    """
    Creates an N x N Hermitian matrix from a flat list of N^2 real parameters.
    N = 2**num_qubits.
    The parameterization follows the structure in the paper[cite: 72].
    params_obs: A list or numpy array of N^2 real numbers.
                The first N are diagonal elements.
                The remaining N(N-1) are for off-diagonal elements (real and imag parts).
    """
    N = 2**num_qubits
    if len(params_obs) != N*N:
        raise ValueError(f"Expected {N*N} parameters for a {N}x{N} Hermitian matrix, "
                         f"but got {len(params_obs)}")

    hermitian_matrix = np.zeros((N, N), dtype=complex)
    param_idx = 0

    # Fill diagonal elements
    for i in range(N):
        hermitian_matrix[i, i] = params_obs[param_idx]
        param_idx += 1

    # Fill off-diagonal elements (upper triangle)
    for i in range(N):
        for j in range(i + 1, N):
            real_part = params_obs[param_idx]
            imag_part = params_obs[param_idx + 1]
            hermitian_matrix[i, j] = real_part + 1j * imag_part
            hermitian_matrix[j, i] = real_part - 1j * imag_part # Ensure Hermiticity
            param_idx += 2
            
    # For Qiskit's Estimator, it's often easier to work with Pauli strings.
    # Here, we construct the matrix directly for clarity of parameterization.
    # To use with Estimator efficiently, one might decompose this matrix
    # into a sum of Pauli operators. For simplicity, we'll return the matrix
    # and use Statevector simulation for expectation, or convert to SparsePauliOp.
    #
    # Note: Converting an arbitrary Hermitian matrix to SparsePauliOp automatically
    # can be non-trivial or result in many terms.
    # If the FWP is designed to output parameters for a specific Pauli decomposition,
    # that would be more direct for the Estimator.
    # For now, let's assume we can create a SparsePauliOp from the matrix for the Estimator.
    # This is feasible for small number of qubits.
    try:
        observable = SparsePauliOp.from_operator(hermitian_matrix)
    except Exception as e:
        print(f"Could not convert matrix to SparsePauliOp directly: {e}")
        print("Returning the matrix. For Estimator, a Pauli decomposition is preferred.")
        return hermitian_matrix # Fallback for direct statevector calculation

    return observable


# --- Define the Variational Quantum Circuit (VQC) ---
def create_vqc(num_qubits, params_vqc, input_data):
    """
    Creates a VQC with data encoding and a parameterized ansatz.
    num_qubits: Number of qubits.
    params_vqc: Parameters for the variational part of the circuit.
    input_data: Classical input data vector (should match feature_dim of ZFeatureMap).
    """
    n_features = num_qubits # Assuming input_data has num_qubits features for ZFeatureMap
    if len(input_data) != n_features:
        raise ValueError(f"Input data length {len(input_data)} does not match "
                         f"feature dimension {n_features} for ZFeatureMap.")

    # 1. Encoding Circuit U(x) [cite: 42]
    # Using ZFeatureMap as an example encoder
    feature_map = ZFeatureMap(feature_dimension=n_features, reps=1)
    
    # 2. Parameterized Variational Circuit W(Theta) [cite: 42]
    # Using TwoLocal as an example ansatz
    # The number of parameters for TwoLocal depends on num_qubits, reps, rotation_blocks, entanglement_blocks
    ansatz = TwoLocal(num_qubits, ['ry', 'rz'], 'cx', 'linear', reps=2) # Example
    
    # Check if the number of VQC parameters matches the ansatz
    if len(params_vqc) != ansatz.num_parameters:
        raise ValueError(f"Expected {ansatz.num_parameters} VQC parameters for TwoLocal, "
                         f"but got {len(params_vqc)}")

    vqc = QuantumCircuit(num_qubits)
    
    # Bind input data to the feature map
    # The feature map parameters are the input data itself
    vqc.compose(feature_map.assign_parameters(input_data), inplace=True)
    vqc.barrier()
    # Bind variational parameters to the ansatz
    vqc.compose(ansatz.assign_parameters(params_vqc), inplace=True)
    
    return vqc

# --- Main Simulation ---
if __name__ == '__main__':
    num_qubits = 2
    N_matrix_dim = 2**num_qubits

    # 1. Simulate classical input data
    # For ZFeatureMap with num_qubits features
    example_input_data = np.random.rand(num_qubits) 
    print(f"Input data (x): {example_input_data}")

    # 2. Simulate the Fast Weight Programmer (FWP)
    # The FWP (a classical NN) would take 'example_input_data' and generate
    # parameters for the VQC and the Observable[cite: 7, 28].
    
    # For VQC (TwoLocal with num_qubits=2, reps=2, ry,rz,cx -> (2+2)*2*2 = 16 parameters)
    # Let's verify num_parameters for TwoLocal specific configuration
    _ansatz_example = TwoLocal(num_qubits, ['ry', 'rz'], 'cx', 'linear', reps=2)
    num_vqc_params = _ansatz_example.num_parameters 
    # print(f"Number of VQC parameters needed by TwoLocal: {num_vqc_params}") # Should be (2+2)*2*2=16 for 2 qubits, 2 reps, ry,rz
    
    # For Observable (N x N Hermitian matrix, N=2^num_qubits, needs N^2 real params) [cite: 72]
    num_obs_params = N_matrix_dim * N_matrix_dim # 4*4 = 16 for 2 qubits

    # Placeholder: FWP generates these parameters
    # In a real scenario, these come from a trained neural network
    # taking 'example_input_data' as input.
    generated_vqc_params = np.random.rand(num_vqc_params)
    generated_obs_params = np.random.rand(num_obs_params) 
    # Ensure diagonal elements for observable are somewhat distinct for testing
    # generated_obs_params[:N_matrix_dim] = np.linspace(0.1, 1.0, N_matrix_dim)


    print(f"FWP generated VQC params (Theta): {generated_vqc_params[:4]}... ({num_vqc_params} total)")
    print(f"FWP generated Observable params (b): {generated_obs_params[:4]}... ({num_obs_params} total)")

    # 3. Create the VQC using FWP-generated parameters
    vqc_instance = create_vqc(num_qubits, generated_vqc_params, example_input_data)
    # print("\nConstructed VQC:")
    # print(vqc_instance.draw(output='text'))

    # 4. Create the learnable Hermitian observable using FWP-generated parameters
    # The observable H(x) is also data-dependent via the FWP [cite: 68]
    learnable_observable = create_hermitian_observable(generated_obs_params, num_qubits)
    if isinstance(learnable_observable, np.ndarray):
        print(f"\nConstructed Learnable Hermitian Observable (Matrix):\n{learnable_observable}")
        # For direct calculation if not SparsePauliOp
        psi = Statevector(vqc_instance)
        expectation_value = psi.expectation_value(learnable_observable).real
    else:
        print(f"\nConstructed Learnable Hermitian Observable (SparsePauliOp):\n{learnable_observable.to_list()}")
        # 5. Calculate Expectation Value <Psi|H(x)|Psi> [cite: 67]
        # Using Qiskit's Estimator primitive
        estimator = Estimator()
        job = estimator.run([vqc_instance], [learnable_observable])
        result = job.result()
        expectation_value = result.values[0]

    print(f"\nCalculated Expectation Value: {expectation_value}")

    # --- Notes on Training ---
    # The FWP (classical neural network) is trained using gradient descent[cite: 57].
    # This involves calculating gradients of a loss function (e.g., classification loss)
    # with respect to the FWP's own weights.
    # The loss function depends on the expectation value computed above.
    # Gradients for VQC parameters (if not fully programmed by FWP but trained separately)
    # can be obtained using methods like parameter-shift rule.
    # Gradients for observable parameters are given by d<H>/db_kl = <d(H)/db_kl>[cite: 85].
    # The end-to-end differentiability allows simultaneous optimization[cite: 6].
